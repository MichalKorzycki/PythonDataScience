{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warsztaty Python w Data Science\n",
    "\n",
    "---\n",
    "## Text Mining - część 2 z 3  \n",
    "\n",
    "### Biblioteki NLP\n",
    "#### - Scikit-Learn\n",
    "#### - NLTK\n",
    "\n",
    "#### - Gensim\n",
    "#### - Spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn\n",
    "- Potężna biblioteka do nauczania maszynowego\n",
    "- Posiada wiele narzędzi do obróbki statystycznej danych tekstowych\n",
    "\n",
    "### NLTK\n",
    "- Biblioteka do przetwarzania języka naturalnego\n",
    "- Posiada wiele narzędzi do obróbki statystycznej danych tekstowych\n",
    "- KORPUSY\n",
    "\n",
    "### Spacy\n",
    "- Dużo wytrenowanych modeli statystycznych do języka\n",
    "- Chyba najlepsze modele do języka polskiego - morfologia, tagging (części mowy)\n",
    "\n",
    "### Gensim\n",
    "- Zbiór najnowszych algorytmów do obróbki danych tekstowych\n",
    "- Word2Vec, CBOW etc. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zadanie 1\n",
    "\n",
    "Podać wyrazy z korpusu o największym `TF-IDF` z pominięciem wyrazów które wystepują _**raz**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 1    2    3\n",
      "life      0.707107  1.0  0.0\n",
      "learning  0.707107  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "myvocabulary = ['life', 'learning']\n",
    "corpus = {1: \"The game of life is a game of everlasting learning\", \n",
    "          2: \"The unexamined life is not worth living\", \n",
    "          3: \"Never stop learning\"}\n",
    "tfidf = TfidfVectorizer(vocabulary = myvocabulary, ngram_range = (1,3))\n",
    "tfs = tfidf.fit_transform(corpus.values())\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "corpus_index = [n for n in corpus]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = pd.read_csv('data\\gumtree-2021-03-09.csv', sep='|')\n",
    "columns = list(data.columns)\n",
    "columns[0] = \"Index\"\n",
    "data.columns=columns\n",
    "data.set_index('Index', drop=True, inplace=True)\n",
    "data.drop([\"title\", \"url\"], axis=1,inplace=True)\n",
    "\n",
    "def no_tags(s):\n",
    "    return re.sub(r'<[^<]+?>','',str(s))\n",
    "\n",
    "data[\"description\"] = data[\"description\"].apply(no_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na sprzedaż piękna kawalerka o powierzchni 24 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mieszkanie dwupokojowe,własnościowe z 1971 r n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPIS INWESTYCJI\\n===============\\nPOWER INVEST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bezpośrednio od dewelopera- brak prowizji 0%- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Na sprzedaż ekskluzywne mieszkanie dwupokojowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description\n",
       "Index                                                   \n",
       "0      Na sprzedaż piękna kawalerka o powierzchni 24 ...\n",
       "1      Mieszkanie dwupokojowe,własnościowe z 1971 r n...\n",
       "2      OPIS INWESTYCJI\\n===============\\nPOWER INVEST...\n",
       "3      Bezpośrednio od dewelopera- brak prowizji 0%- ...\n",
       "4      Na sprzedaż ekskluzywne mieszkanie dwupokojowe..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import sys\n",
    "import re\n",
    "\n",
    "f = gzip.open('data/odm.txt.gz', 'rt', encoding='utf-8')\n",
    "dictionary = {}\n",
    "\n",
    "for x in f:\n",
    "    t = x.strip().split(',')\n",
    "    tt = [ x.strip().lower() for x in t]\n",
    "    for w in tt[1:]: \n",
    "        dictionary[w]=tt[0]\n",
    "\n",
    "def lematize(w):\n",
    "    return dictionary.get(w,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "splitter = re.compile(r'[^ąąćęńłóóśśżżź\\w]+')\n",
    "isnumber = re.compile(r'[0-9]')\n",
    "\n",
    "def preprocessing(opis):\n",
    "    opis = str(opis)\n",
    "    \n",
    "    tokenized = splitter.split(opis)\n",
    "    l = list(tokenized)\n",
    "    l = [ x.lower() for x in l if len(x)>2 ]\n",
    "    l = [ x for x in l if isnumber.search(x) is None ]\n",
    "    l = [ lematize(x) for x in l ]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_description\"] = data[\"description\"].apply(lambda x: ' '.join(preprocessing(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na sprzedaż piękna kawalerka o powierzchni 24 ...</td>\n",
       "      <td>sprzedaż piękny kawalerka powierzchnia ostatni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mieszkanie dwupokojowe,własnościowe z 1971 r n...</td>\n",
       "      <td>mieszkać dwupokojowy własnościowy pierwszy pię...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPIS INWESTYCJI\\n===============\\nPOWER INVEST...</td>\n",
       "      <td>opis inwestycja power invest przyjemność zapre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bezpośrednio od dewelopera- brak prowizji 0%- ...</td>\n",
       "      <td>bezpośredni deweloper brak prowizja brak podat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Na sprzedaż ekskluzywne mieszkanie dwupokojowe...</td>\n",
       "      <td>sprzedaż ekskluzywny mieszkać dwupokojowy powi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "Index                                                      \n",
       "0      Na sprzedaż piękna kawalerka o powierzchni 24 ...   \n",
       "1      Mieszkanie dwupokojowe,własnościowe z 1971 r n...   \n",
       "2      OPIS INWESTYCJI\\n===============\\nPOWER INVEST...   \n",
       "3      Bezpośrednio od dewelopera- brak prowizji 0%- ...   \n",
       "4      Na sprzedaż ekskluzywne mieszkanie dwupokojowe...   \n",
       "\n",
       "                                       clean_description  \n",
       "Index                                                     \n",
       "0      sprzedaż piękny kawalerka powierzchnia ostatni...  \n",
       "1      mieszkać dwupokojowy własnościowy pierwszy pię...  \n",
       "2      opis inwestycja power invest przyjemność zapre...  \n",
       "3      bezpośredni deweloper brak prowizja brak podat...  \n",
       "4      sprzedaż ekskluzywny mieszkać dwupokojowy powi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = {1: \"The game of life is a game of everlasting learning\", \n",
    "          2: \"The unexamined life is not worth living\", \n",
    "          3: \"Never stop learning\"}\n",
    "tfidf = TfidfVectorizer(min_df=2)\n",
    "tfs = tfidf.fit_transform(data[\"clean_description\"])\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aby', 'aczkolwiek', 'adaptacja', 'adres', 'agd', 'agencja', 'agent', 'aktualność', 'aktualny', 'aktywny', 'al', 'alejka', 'aluzyjny', 'amator', 'amfiteatr', 'andrychowicznieruchomosci', 'aneks', 'antresola', 'antywłamaniowy', 'apartament', 'apartamentowiec', 'apteka', 'aranżacja', 'aranżacyjny', 'architektoniczny', 'architektura', 'arkadia', 'armatura', 'art', 'atmosfera', 'atrakcja', 'atrakcjekomunikacja', 'atrakcyjny', 'atut', 'aut', 'autobus', 'autobusowy', 'bagno', 'bajkowy', 'balance', 'balkon', 'bank', 'bar', 'bardzo', 'basen', 'baza', 'bazarek', 'bazia', 'bem', 'bemowo']\n"
     ]
    }
   ],
   "source": [
    "print(list(feature_names[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tfs.toarray(), \n",
    "columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aby</th>\n",
       "      <th>aczkolwiek</th>\n",
       "      <th>adaptacja</th>\n",
       "      <th>adres</th>\n",
       "      <th>agd</th>\n",
       "      <th>agencja</th>\n",
       "      <th>agent</th>\n",
       "      <th>aktualność</th>\n",
       "      <th>aktualny</th>\n",
       "      <th>aktywny</th>\n",
       "      <th>...</th>\n",
       "      <th>świetny</th>\n",
       "      <th>świeży</th>\n",
       "      <th>żaden</th>\n",
       "      <th>żerać</th>\n",
       "      <th>żerań</th>\n",
       "      <th>żerańogłoszenie</th>\n",
       "      <th>życzyć</th>\n",
       "      <th>żyto</th>\n",
       "      <th>żyć</th>\n",
       "      <th>żłobek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.141596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.099201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.097644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 1334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aby  aczkolwiek  adaptacja     adres       agd  agencja  agent  \\\n",
       "0    0.000000         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "1    0.000000         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "2    0.000000         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "3    0.000000         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "4    0.117810         0.0        0.0  0.000000  0.061704      0.0    0.0   \n",
       "..        ...         ...        ...       ...       ...      ...    ...   \n",
       "219  0.099201         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "220  0.097644         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "221  0.073988         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "222  0.000000         0.0        0.0  0.000000  0.000000      0.0    0.0   \n",
       "223  0.049656         0.0        0.0  0.201406  0.000000      0.0    0.0   \n",
       "\n",
       "     aktualność  aktualny  aktywny  ...   świetny  świeży  żaden     żerać  \\\n",
       "0           0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "1           0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "2           0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "3           0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "4           0.0  0.059788      0.0  ...  0.044939     0.0    0.0  0.000000   \n",
       "..          ...       ...      ...  ...       ...     ...    ...       ...   \n",
       "219         0.0  0.100689      0.0  ...  0.000000     0.0    0.0  0.308448   \n",
       "220         0.0  0.099108      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "221         0.0  0.075098      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "222         0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "223         0.0  0.000000      0.0  ...  0.000000     0.0    0.0  0.000000   \n",
       "\n",
       "     żerań  żerańogłoszenie    życzyć  żyto       żyć  żłobek  \n",
       "0      0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "1      0.0          0.00000  0.141596   0.0  0.000000     0.0  \n",
       "2      0.0          0.00000  0.000000   0.0  0.061946     0.0  \n",
       "3      0.0          0.00000  0.000000   0.0  0.093885     0.0  \n",
       "4      0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "..     ...              ...       ...   ...       ...     ...  \n",
       "219    0.0          0.12965  0.000000   0.0  0.000000     0.0  \n",
       "220    0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "221    0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "222    0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "223    0.0          0.00000  0.000000   0.0  0.000000     0.0  \n",
       "\n",
       "[224 rows x 1334 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Na sprzedaż piękna kawalerka o powierzchni 24 m2 na ostatnim piętrze 10 piętrowego bloku z oknem wychodzącym na spokojną stronę osiedla. Bardzo dobrze skomunikowane z centrum (tramwaje ,autobusy).W pobliżu znajduje się dobra infrastruktura: sklepy, apteka, szkoła, targowisko ( hala Banacha),oraz park szczęśliwicki (5 minut na piechotę).Mieszkanie słoneczne i bardzo ustawne ,budynek po wymianie windy i elektryki w częściach wspólnych.Serdecznie zapraszamy do kontaktu.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opis = data['description'][0]\n",
    "opis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Na', 'sprzedaż', 'piękna', 'kawalerka', 'o', 'powierzchni', '24', 'm2', 'na', 'ostatnim', 'piętrze', '10', 'piętrowego', 'bloku', 'z', 'oknem', 'wychodzącym', 'na', 'spokojną', 'stronę', 'osiedla', '.', 'Bardzo', 'dobrze', 'skomunikowane', 'z', 'centrum', '(', 'tramwaje', ',', 'autobusy', ')', '.W', 'pobliżu', 'znajduje', 'się', 'dobra', 'infrastruktura', ':', 'sklepy', ',', 'apteka', ',', 'szkoła', ',', 'targowisko', '(', 'hala', 'Banacha', ')', ',', 'oraz', 'park', 'szczęśliwicki', '(', '5', 'minut', 'na', 'piechotę', ')', '.Mieszkanie', 'słoneczne', 'i', 'bardzo', 'ustawne', ',', 'budynek', 'po', 'wymianie', 'windy', 'i', 'elektryki', 'w', 'częściach', 'wspólnych.Serdecznie', 'zapraszamy', 'do', 'kontaktu', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(opis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Na sprzedaż piękna kawalerka o powierzchni 24 m2 na ostatnim piętrze 10 '\n",
      " 'piętrowego bloku z oknem wychodzącym na spokojną stronę osiedla.',\n",
      " 'Bardzo dobrze skomunikowane z centrum (tramwaje ,autobusy).W pobliżu '\n",
      " 'znajduje się dobra infrastruktura: sklepy, apteka, szkoła, targowisko ( hala '\n",
      " 'Banacha),oraz park szczęśliwicki (5 minut na piechotę).Mieszkanie słoneczne '\n",
      " 'i bardzo ustawne ,budynek po wymianie windy i elektryki w częściach '\n",
      " 'wspólnych.Serdecznie zapraszamy do kontaktu.']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sent_tokenize(opis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Na', 'sprzedaż', 'piękna', 'kawalerka', 'o', 'powierzchni', '24', 'm2', 'na', 'ostatnim', 'piętrze', '10', 'piętrowego', 'bloku', 'z', 'oknem', 'wychodzącym', 'na', 'spokojną', 'stronę', 'osiedla', '.']\n",
      "['Bardzo', 'dobrze', 'skomunikowane', 'z', 'centrum', '(', 'tramwaje', ',', 'autobusy', ')', '.W', 'pobliżu', 'znajduje', 'się', 'dobra', 'infrastruktura', ':', 'sklepy', ',', 'apteka', ',', 'szkoła', ',', 'targowisko', '(', 'hala', 'Banacha', ')', ',', 'oraz', 'park', 'szczęśliwicki', '(', '5', 'minut', 'na', 'piechotę', ')', '.Mieszkanie', 'słoneczne', 'i', 'bardzo', 'ustawne', ',', 'budynek', 'po', 'wymianie', 'windy', 'i', 'elektryki', 'w', 'częściach', 'wspólnych.Serdecznie', 'zapraszamy', 'do', 'kontaktu', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [ word_tokenize(sentence) for sentence in sent_tokenize(opis)]\n",
    "for sentence in tokens:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Katerina Ivanovna',\n",
       " 'Pyotr Petrovitch',\n",
       " 'Pulcheria Alexandrovna',\n",
       " 'Avdotya Romanovna',\n",
       " 'Rodion Romanovitch',\n",
       " 'Marfa Petrovna',\n",
       " 'Sofya Semyonovna',\n",
       " 'old woman',\n",
       " 'Project Gutenberg-tm',\n",
       " 'Porfiry Petrovitch',\n",
       " 'Amalia Ivanovna',\n",
       " 'great deal',\n",
       " 'young man',\n",
       " 'Nikodim Fomitch',\n",
       " 'Ilya Petrovitch',\n",
       " 'Project Gutenberg',\n",
       " 'Andrey Semyonovitch',\n",
       " 'Hay Market',\n",
       " 'Dmitri Prokofitch',\n",
       " 'Good heavens']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "text.collocation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mock Turtle',\n",
       " 'said Alice',\n",
       " 'March Hare',\n",
       " 'White Rabbit',\n",
       " 'thought Alice',\n",
       " 'golden key',\n",
       " 'beautiful Soup',\n",
       " 'white kid',\n",
       " 'good deal',\n",
       " 'kid gloves',\n",
       " 'Mary Ann',\n",
       " 'yer honour',\n",
       " 'three gardeners',\n",
       " 'play croquet',\n",
       " 'Lobster Quadrille',\n",
       " 'ootiful Soo',\n",
       " 'great hurry',\n",
       " 'old fellow',\n",
       " 'trembling voice',\n",
       " 'poor little',\n",
       " 'next witness',\n",
       " 'feet high',\n",
       " 'poor Alice',\n",
       " 'inches high',\n",
       " 'young lady']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = nltk.corpus.gutenberg.fileids()[7]\n",
    "al = nltk.corpus.gutenberg.words(alice)\n",
    "al_text = nltk.Text(al)\n",
    "al_text.collocation_list(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pol'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "#opis=\"Ala ma kota, kto tam przyszedł\"\n",
    "\n",
    "tc = nltk.classify.textcat.TextCat() \n",
    "tc.guess_language(opis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download pl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poczuł przyjemną woń mocnej kawy.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.pl.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poczuł VERB ROOT\n",
      "przyjemną ADJ amod\n",
      "woń ADV obj\n",
      "mocnej ADJ amod\n",
      "kawy NOUN obj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na sprzedaż piękna kawalerka o powierzchni 24 m2 na ostatnim piętrze 10 piętrowego bloku z oknem wychodzącym na spokojną stronę osiedla. Bardzo dobrze skomunikowane z centrum (tramwaje ,autobusy).W pobliżu znajduje się dobra infrastruktura: sklepy, apteka, szkoła, targowisko ( hala Banacha),oraz park szczęśliwicki (5 minut na piechotę).Mieszkanie słoneczne i bardzo ustawne ,budynek po wymianie windy i elektryki w częściach wspólnych.Serdecznie zapraszamy do kontaktu.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(opis)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na ADP case\n",
      "sprzedaż NOUN amod\n",
      "piękna ADJ amod\n",
      "kawalerka NOUN ROOT\n",
      "o ADP case\n",
      "powierzchni NOUN nmod\n",
      "24 NUM nummod\n",
      "m2 NOUN nmod\n",
      "na ADP case\n",
      "ostatnim ADJ amod\n",
      "piętrze NOUN nmod\n",
      "10 PRON amod\n",
      "piętrowego ADJ amod\n",
      "bloku NOUN nmod\n",
      "z ADP case\n",
      "oknem NOUN nmod\n",
      "wychodzącym ADJ amod\n",
      "na ADP case\n",
      "spokojną ADJ amod\n",
      "stronę NOUN obl:arg\n",
      "osiedla NOUN nmod\n",
      ". PUNCT punct\n",
      "Bardzo ADV advmod\n",
      "dobrze ADV advmod\n",
      "skomunikowane ADJ amod\n",
      "z ADP case\n",
      "centrum NOUN obl\n",
      "( PUNCT punct\n",
      "tramwaje NOUN nsubj\n",
      ", PUNCT punct\n",
      "autobusy).W NOUN amod\n",
      "pobliżu NOUN conj\n",
      "znajduje VERB ROOT\n",
      "się PRON expl:pv\n",
      "dobra ADJ amod\n",
      "infrastruktura NOUN nsubj\n",
      ": ADJ nmod\n",
      "sklepy NOUN obj\n",
      ", PUNCT punct\n",
      "apteka VERB conj\n",
      ", PUNCT punct\n",
      "szkoła NOUN conj\n",
      ", PUNCT punct\n",
      "targowisko ADJ conj\n",
      "( PUNCT punct\n",
      "hala NOUN appos\n",
      "Banacha),oraz CCONJ nmod\n",
      "park NOUN conj\n",
      "szczęśliwicki ADJ amod\n",
      "( PUNCT punct\n",
      "5 NUM nmod\n",
      "minut NOUN nmod\n",
      "na ADP case\n",
      "piechotę).Mieszkanie NOUN nmod\n",
      "słoneczne ADJ amod\n",
      "i CCONJ cc\n",
      "bardzo ADV advmod\n",
      "ustawne ADJ amod\n",
      ", PUNCT punct\n",
      "budynek NOUN conj\n",
      "po ADP case\n",
      "wymianie NOUN nmod\n",
      "windy NOUN nmod\n",
      "i CCONJ cc\n",
      "elektryki NOUN conj\n",
      "w ADP case\n",
      "częściach NOUN nmod\n",
      "wspólnych ADJ amod\n",
      ". PUNCT punct\n",
      "Serdecznie ADV advmod\n",
      "zapraszamy VERB ROOT\n",
      "do ADP case\n",
      "kontaktu NOUN obl:arg\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gensim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec - model wektorowy słów w oparciu o sieci neuronowe (płytkie) - ale mówi się na to Deep Learning\n",
    "\n",
    "### vec(“king”) - vec(“man”) + vec(“woman”) =~ vec(“queen”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
