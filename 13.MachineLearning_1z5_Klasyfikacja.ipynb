{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warsztaty Python w Data Science\n",
    "\n",
    "---\n",
    "\n",
    "# \"Machine Learning is done in Python, A.I. in PowerPoint.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "### 1. Wprowadzenie. Klasyfikacja\n",
    "### 2. Walidacja krzyżowa. Regresja\n",
    "### 3. Optymalizacja hiperparametrów. Grid Search\n",
    "### 4. Nauczanie bez nadzoru. Klasteryzacja\n",
    "### 5. Reinforcement Learning\n",
    "---\n",
    "## Machine Learning - część 1 z 5. Wprowadzenie. Klasyfikacja  \n",
    "\n",
    "### Wprowadzenie\n",
    "#### Podstawowe pojęcia\n",
    "#### Kompromis między obciążeniem a wariancją\n",
    "#### Proces machine learning\n",
    "#### Przykład klasyfikacji\n",
    "#### Ocena wyników\n",
    "#### Rodzaje klasyfikatorów\n",
    "---\n",
    "\n",
    "\n",
    "![AI](img\\AI1.png)\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Machine_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Nauczanie Maszynowe (_Machine Learning_)\n",
    "\n",
    "- Z nadzorem (_supervised_)\n",
    "- Bez nadzoru (_unsupervised_)\n",
    "\n",
    "## Nauczanie Maszynowe bez nadzoru\n",
    "- Klasteryzacja\n",
    "- Reguły asocjacyjne\n",
    "\n",
    "## Nauczanie Maszynowe z nadzorem\n",
    "- Klasyfikacja \n",
    "- Regresja\n",
    "\n",
    "---\n",
    "​\n",
    "### Dla zmiennych tłumaczących `X` szukamy funkcji `f` która jak najlepiej odzwierciedli nam dane tłumaczone `y`\n",
    "​\n",
    "$$ \n",
    "y \\approx f (X)\n",
    "$$\n",
    "​\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"dark_background\")\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"dark_background\")\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, x-0.6*x*x)\n",
    "\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, x-0.6*x*x)\n",
    "plt.plot(x, 1.0*x)\n",
    "x = np.linspace(-1, 1, 10)\n",
    "plt.scatter(x, x-0.5*np.abs(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, x-0.6*x*x)\n",
    "plt.plot(x, 1*x)\n",
    "x = np.linspace(-10, 10, 25)\n",
    "plt.scatter(x, x-0.5*np.abs(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kompromis między obciążeniem a wariancją\n",
    "### ang. *bias-variance tradeoff*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Bias~[~\\hat{f}(x)~] = E~[~\\hat{f}(x)~] - f(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Var~[~\\hat{f}(x)~] = E~[~\\hat{f}(x)^2~] - E~[~\\hat{f}(x)~]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Proces nauczania w Machine Learning\n",
    "\n",
    "1. Przygotowanie danych\n",
    "2. Podział danych\n",
    "3. Budowanie modelu\n",
    "4. Test dokładności"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'v1':'class_label', 'v2':'message'}, inplace = True)\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as ab\n",
    "import numpy as np\n",
    "labels = ['ham', 'spam']\n",
    "counts = [4825, 747]\n",
    "ypos = np.arange(len(labels)) #converting text labels to numberic value, 0 and 1\n",
    "ypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.xticks(ypos, labels)\n",
    "ab.xlabel(\"class label\")\n",
    "ab.ylabel(\"Frequency\")\n",
    "ab.title(\"# of spam and ham in dataset\")\n",
    "ab.bar(ypos, counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_label'] = df['class_label'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['message'], df['class_label'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows in test set: ' + str(x_test.shape))\n",
    "print('rows in train set: ' + str(x_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = x_train.tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "input= data ,  \n",
    "lowercase=True,      \n",
    "stop_words='english' \n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(data)  \n",
    "features_test_transformed  = vectorizer.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features_train_transformed.toarray(), columns = vectorizer.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# train the model\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# train the model\n",
    "classifier = SVC()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PrecisionRecall](img\\Precisionrecall.svg.png)\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład:\n",
    "    \n",
    "- 990 \"ham\"\n",
    "- 10 \"spam\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy - dokładność - % prawidłowych odpowiedzi\n",
    "\n",
    "\"Wszystko ham\" - 99%\n",
    "\n",
    "Precision - precyzja - jaki % poprawności odpowiedzi (błedy pierwszego rodzaju)\n",
    "\n",
    "\"Wszystko ham\" - 99% w ham, 0% w spam\n",
    "\n",
    "Recall - zupełność - jaki % poprawnych znalazł (błedy pierwszego rodzaju)\n",
    "\n",
    "\"Wszystko ham\" - 100% w ham, 0% w spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classifier.predict(features_test_transformed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "actual = y_test.tolist()\n",
    "predicted = labels\n",
    "results = confusion_matrix(actual, predicted)\n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted) )\n",
    "score_2 = f1_score(actual, predicted, average = 'binary')\n",
    "print('F-Measure: %.3f' % score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                results.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     results.flatten()/np.sum(results)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(results, annot=labels, fmt='', cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# train the model\n",
    "classifier = SVC()\n",
    "classifier.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classifier.predict(features_test_transformed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "actual = y_test.tolist()\n",
    "predicted = labels\n",
    "results = confusion_matrix(actual, predicted)\n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted) )\n",
    "score_2 = f1_score(actual, predicted, average = 'binary')\n",
    "print('F-Measure: %.3f' % score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                results.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     results.flatten()/np.sum(results)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(results, annot=labels, fmt='', cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Kompromis między jakością wyniku a interpretowalnością modelu\n",
    "\n",
    "# Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "treeclf = tree.DecisionTreeClassifier(random_state=0)\n",
    "treeclf.fit(features_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                results.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     results.flatten()/np.sum(results)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(results, annot=labels, fmt='', cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.style.use(\"classic\")\n",
    "plt.figure(figsize=(18,12))\n",
    "tree.plot_tree(treeclf, max_depth=5, feature_names=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokonane uproszczenia\n",
    "- ## Niewyczyszczone dane\n",
    "- ## Niezbalansowane klasy\n",
    "- ## Brak walidacji krzyżowej \n",
    "\n",
    "(ale to za tydzień...) \n",
    "\n",
    "https://towardsdatascience.com/how-to-build-your-first-spam-classifier-in-10-steps-fdbf5b1b3870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
